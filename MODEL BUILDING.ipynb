{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a66f460f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd396a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f40f146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>is_duplicate</th>\n",
       "      <th>cwc_min</th>\n",
       "      <th>cwc_max</th>\n",
       "      <th>csc_min</th>\n",
       "      <th>csc_max</th>\n",
       "      <th>ctc_min</th>\n",
       "      <th>ctc_max</th>\n",
       "      <th>last_word_eq</th>\n",
       "      <th>...</th>\n",
       "      <th>290_y</th>\n",
       "      <th>291_y</th>\n",
       "      <th>292_y</th>\n",
       "      <th>293_y</th>\n",
       "      <th>294_y</th>\n",
       "      <th>295_y</th>\n",
       "      <th>296_y</th>\n",
       "      <th>297_y</th>\n",
       "      <th>298_y</th>\n",
       "      <th>299_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.833319</td>\n",
       "      <td>0.714276</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.999980</td>\n",
       "      <td>0.833326</td>\n",
       "      <td>0.714281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-17.810438</td>\n",
       "      <td>7.231024</td>\n",
       "      <td>1.531186</td>\n",
       "      <td>-7.528823</td>\n",
       "      <td>0.473802</td>\n",
       "      <td>-11.864658</td>\n",
       "      <td>-11.293788</td>\n",
       "      <td>1.866265</td>\n",
       "      <td>3.616046</td>\n",
       "      <td>11.971096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.599988</td>\n",
       "      <td>0.299997</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.333322</td>\n",
       "      <td>0.499994</td>\n",
       "      <td>0.307690</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>23.015827</td>\n",
       "      <td>3.435464</td>\n",
       "      <td>-5.169600</td>\n",
       "      <td>7.102491</td>\n",
       "      <td>34.516881</td>\n",
       "      <td>6.177686</td>\n",
       "      <td>-27.770856</td>\n",
       "      <td>12.926435</td>\n",
       "      <td>-4.564559</td>\n",
       "      <td>33.919834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333328</td>\n",
       "      <td>0.249997</td>\n",
       "      <td>0.249994</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.299997</td>\n",
       "      <td>0.214284</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-24.310109</td>\n",
       "      <td>-1.216773</td>\n",
       "      <td>11.909693</td>\n",
       "      <td>9.591573</td>\n",
       "      <td>11.846737</td>\n",
       "      <td>1.397859</td>\n",
       "      <td>6.454157</td>\n",
       "      <td>-0.271460</td>\n",
       "      <td>-12.500337</td>\n",
       "      <td>27.634567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.435584</td>\n",
       "      <td>1.672591</td>\n",
       "      <td>-0.863278</td>\n",
       "      <td>-2.906553</td>\n",
       "      <td>-3.466688</td>\n",
       "      <td>-3.867892</td>\n",
       "      <td>-4.249463</td>\n",
       "      <td>-12.551012</td>\n",
       "      <td>4.494087</td>\n",
       "      <td>-6.223341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.166664</td>\n",
       "      <td>0.090908</td>\n",
       "      <td>0.999900</td>\n",
       "      <td>0.499975</td>\n",
       "      <td>0.285710</td>\n",
       "      <td>0.153845</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-10.407441</td>\n",
       "      <td>-8.444207</td>\n",
       "      <td>-14.450059</td>\n",
       "      <td>-12.709382</td>\n",
       "      <td>-4.449050</td>\n",
       "      <td>12.563987</td>\n",
       "      <td>-11.721362</td>\n",
       "      <td>-16.459300</td>\n",
       "      <td>3.626297</td>\n",
       "      <td>-9.790615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 629 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  id  is_duplicate   cwc_min   cwc_max   csc_min   csc_max  \\\n",
       "0           0   0             0  0.833319  0.714276  0.999980  0.999980   \n",
       "1           1   1             0  0.599988  0.299997  0.499975  0.333322   \n",
       "2           2   2             0  0.333328  0.249997  0.249994  0.166664   \n",
       "3           3   3             0  0.000000  0.000000  0.000000  0.000000   \n",
       "4           4   4             0  0.166664  0.090908  0.999900  0.499975   \n",
       "\n",
       "    ctc_min   ctc_max  last_word_eq  ...      290_y     291_y      292_y  \\\n",
       "0  0.833326  0.714281           0.0  ... -17.810438  7.231024   1.531186   \n",
       "1  0.499994  0.307690           0.0  ...  23.015827  3.435464  -5.169600   \n",
       "2  0.299997  0.214284           0.0  ... -24.310109 -1.216773  11.909693   \n",
       "3  0.000000  0.000000           0.0  ...  -5.435584  1.672591  -0.863278   \n",
       "4  0.285710  0.153845           0.0  ... -10.407441 -8.444207 -14.450059   \n",
       "\n",
       "       293_y      294_y      295_y      296_y      297_y      298_y      299_y  \n",
       "0  -7.528823   0.473802 -11.864658 -11.293788   1.866265   3.616046  11.971096  \n",
       "1   7.102491  34.516881   6.177686 -27.770856  12.926435  -4.564559  33.919834  \n",
       "2   9.591573  11.846737   1.397859   6.454157  -0.271460 -12.500337  27.634567  \n",
       "3  -2.906553  -3.466688  -3.867892  -4.249463 -12.551012   4.494087  -6.223341  \n",
       "4 -12.709382  -4.449050  12.563987 -11.721362 -16.459300   3.626297  -9.790615  \n",
       "\n",
       "[5 rows x 629 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "71f60927",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e2dbaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = df['is_duplicate']\n",
    "df.drop(['Unnamed: 0', 'id', 'is_duplicate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26974b3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(404287, 626)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46780432",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1ee29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test, y_train, y_test = train_test_split(df, y_true, stratify=y_true, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51934d4f",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93f9e950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8c51fb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "716bff85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8365612143098601"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "56e57537",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70101,  6407],\n",
       "       [13416, 31363]], dtype=int64)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea281fc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.84      0.92      0.88     76508\\n           1       0.83      0.70      0.76     44779\\n\\n    accuracy                           0.84    121287\\n   macro avg       0.83      0.81      0.82    121287\\nweighted avg       0.84      0.84      0.83    121287\\n'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece3574d",
   "metadata": {},
   "source": [
    "### Hyperparameter of Random Forest using RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c0e0d557",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e9884356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "39 fits failed out of a total of 50.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 187, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 214, in fit\n",
      "    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n",
      "  File \"<__array_function__ internals>\", line 180, in unique\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 272, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 330, in _unique1d\n",
      "    perm = ar.argsort(kind='mergesort' if return_index else 'quicksort')\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.73 MiB for an array with shape (226400,) and data type int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "3 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\generic.py\", line 2072, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 541. MiB for an array with shape (226400, 626) and data type float32\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 203, in fit\n",
      "    check_classification_targets(y)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 189, in check_classification_targets\n",
      "    y_type = type_of_target(y)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\multiclass.py\", line 327, in type_of_target\n",
      "    if (len(np.unique(y)) > 2) or (y.ndim >= 2 and len(y[0]) > 1):\n",
      "  File \"<__array_function__ internals>\", line 180, in unique\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 272, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 325, in _unique1d\n",
      "    ar = np.asanyarray(ar).flatten()\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.73 MiB for an array with shape (226400,) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "31 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 327, in fit\n",
      "    X, y = self._validate_data(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\base.py\", line 581, in _validate_data\n",
      "    X, y = check_X_y(X, y, **check_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 964, in check_X_y\n",
      "    X = check_array(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\validation.py\", line 746, in check_array\n",
      "    array = np.asarray(array, order=order, dtype=dtype)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\generic.py\", line 2072, in __array__\n",
      "    return np.asarray(self._values, dtype=dtype)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\frame.py\", line 918, in _values\n",
      "    return self.values\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\frame.py\", line 10877, in values\n",
      "    return self._mgr.as_array()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1589, in as_array\n",
      "    arr = self._interleave(dtype=dtype, na_value=na_value)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\pandas\\core\\internals\\managers.py\", line 1628, in _interleave\n",
      "    result = np.empty(self.shape, dtype=dtype)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.06 GiB for an array with shape (626, 226400) and data type float64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 175, in _parallel_build_trees\n",
      "    sample_counts = np.bincount(indices, minlength=n_samples)\n",
      "  File \"<__array_function__ internals>\", line 180, in bincount\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.73 MiB for an array with shape (226400,) and data type int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 420, in fit\n",
      "    builder.build(self.tree_, X, y, sample_weight)\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 131, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 227, in sklearn.tree._tree.DepthFirstTreeBuilder.build\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 724, in sklearn.tree._tree.Tree._add_node\n",
      "  File \"sklearn\\tree\\_tree.pyx\", line 695, in sklearn.tree._tree.Tree._resize_c\n",
      "  File \"sklearn\\tree\\_utils.pyx\", line 37, in sklearn.tree._utils.safe_realloc\n",
      "MemoryError: could not allocate 1835008 bytes\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "1 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 450, in fit\n",
      "    trees = Parallel(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 1046, in __call__\n",
      "    while self.dispatch_one_batch(iterator):\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 861, in dispatch_one_batch\n",
      "    self._dispatch(tasks)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 779, in _dispatch\n",
      "    job = self._backend.apply_async(batch, callback=cb)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 208, in apply_async\n",
      "    result = ImmediateResult(func)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\_parallel_backends.py\", line 572, in __init__\n",
      "    self.results = batch()\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in __call__\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\joblib\\parallel.py\", line 262, in <listcomp>\n",
      "    return [func(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\utils\\fixes.py\", line 216, in __call__\n",
      "    return self.function(*args, **kwargs)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\", line 185, in _parallel_build_trees\n",
      "    tree.fit(X, y, sample_weight=curr_sample_weight, check_input=False)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 937, in fit\n",
      "    super().fit(\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\tree\\_classes.py\", line 214, in fit\n",
      "    classes_k, y_encoded[:, k] = np.unique(y[:, k], return_inverse=True)\n",
      "  File \"<__array_function__ internals>\", line 180, in unique\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 272, in unique\n",
      "    ret = _unique1d(ar, return_index, return_inverse, return_counts)\n",
      "  File \"C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\numpy\\lib\\arraysetops.py\", line 355, in _unique1d\n",
      "    inv_idx = np.empty(mask.shape, dtype=np.intp)\n",
      "numpy.core._exceptions._ArrayMemoryError: Unable to allocate 1.73 MiB for an array with shape (226400,) and data type int64\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan nan nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(estimator=RandomForestClassifier(), n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'criterion': ['gini', 'entropy'],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000, 2500,\n",
       "                                                         3000]},\n",
       "                   verbose=10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf=RandomForestClassifier()\n",
    "\n",
    "params={\n",
    "     'n_estimators':[200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000, 2500, 3000],\n",
    "     'max_features' : ['auto', 'sqrt'],\n",
    "     'max_depth':[10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None],\n",
    "     'min_samples_leaf': [1, 2, 4],\n",
    "     'min_samples_split': [2, 5, 10],\n",
    "     'criterion' : ['gini', 'entropy'],\n",
    "     'bootstrap': [True, False]\n",
    "}\n",
    "random_cfl1=RandomizedSearchCV(rf_clf,param_distributions=params,verbose=10,n_jobs=-1,)\n",
    "random_cfl1.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2813d59b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 2000, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'auto', 'max_depth': 50, 'criterion': 'entropy', 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "print (random_cfl1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "039d2265",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf_cfl2=RandomForestClassifier(n_estimators=2000, min_samples_split=10, min_samples_leaf=1, max_depth=50, max_features='auto', \n",
    "                     criterion='entropy', bootstrap=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dda1b84f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=False, criterion='entropy', max_depth=50,\n",
       "                       min_samples_split=10, n_estimators=2000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_cfl2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c2090dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_tuned = rf_cfl2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "627087cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.848310206370015"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "496f21ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70270,  6238],\n",
       "       [12160, 32619]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,y_pred_tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86f2c487",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20ea7022",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(rf_cfl2, open('model.pkl','wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0de487a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "843df84c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\xgboost\\data.py:262: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  elif isinstance(data.columns, (pd.Int64Index, pd.RangeIndex)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:41:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=16,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "255bdc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = xgb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04aa1d63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.84326432346418"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "934a8a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[68264,  8244],\n",
       "       [10766, 34013]], dtype=int64)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26a3594c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.86      0.89      0.88     76508\\n           1       0.80      0.76      0.78     44779\\n\\n    accuracy                           0.84    121287\\n   macro avg       0.83      0.83      0.83    121287\\nweighted avg       0.84      0.84      0.84    121287\\n'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,y_pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2101e05e",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "858f10bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4748ccd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arjun\\anaconda3\\envs\\quora\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e24fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred2 = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f36fbcec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7745842505792047"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d90a706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "494ed72a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'              precision    recall  f1-score   support\\n\\n           0       0.80      0.86      0.83     76508\\n           1       0.72      0.63      0.67     44779\\n\\n    accuracy                           0.77    121287\\n   macro avg       0.76      0.74      0.75    121287\\nweighted avg       0.77      0.77      0.77    121287\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classification_report(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5407814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65737, 10771],\n",
       "       [16569, 28210]], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbde2b79",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f09aead2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da8ae8c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_clf = svm.SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83049bb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8fd3285b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred3 = svc_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b0d7fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8215637290064063"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "accuracy_score(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a2bf19c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[67773,  8735],\n",
       "       [12907, 31872]], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,y_pred3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2dcf213",
   "metadata": {},
   "source": [
    "### We have chosen Random Forest Classifier and tuned it further to get our best classifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0127fc2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
